{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('diabetes-v2/data/predictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encounter_id', 'patient_nbr', 'race', 'gender', 'age',\n",
       "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
       "       'medical_specialty', 'num_lab_procedures', 'num_procedures',\n",
       "       'num_medications', 'number_outpatient', 'number_emergency',\n",
       "       'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses',\n",
       "       'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide',\n",
       "       'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'tolazamide',\n",
       "       'insulin', 'glyburide-metformin', 'change', 'diabetesMed',\n",
       "       'Risk30DayReadmission', 'RiskAnyReadmission',\n",
       "       'Risk30DayReadmissionPercentile', 'RiskLongStay',\n",
       "       'ExpectedHospitalStay', 'ScoringTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_33 = df['LGBM_score'].quantile(0.33)\n",
    "percentile_66 = df['LGBM_score'].quantile(0.66)\n",
    "# percentile_30 = df['LGBM_score'].quantile(0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate percentiles\n",
    "percentile_30 = df[column].quantile(0.30)\n",
    "percentile_50 = df[column].quantile(0.50)\n",
    "percentile_80 = df[column].quantile(0.80)\n",
    "percentile_90 = df[column].quantile(0.90)\n",
    "\n",
    "# Create column1 based on the given conditions with weighted random choices\n",
    "def calculate_column1(score):\n",
    "    if score < percentile_30:\n",
    "        return 'low risk'\n",
    "    elif score < percentile_80:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.45, 0.45, 0.1])\n",
    "    else:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.1, 0.6, 0.3])\n",
    "\n",
    "df['advisory_30_cutoff'] = df['Risk30DayReadmission'].apply(calculate_column1)\n",
    "\n",
    "# Create column2 based on the given conditions with weighted random choices\n",
    "def calculate_column2(score):\n",
    "    if score < percentile_50:\n",
    "        return 'low risk'\n",
    "    elif score < percentile_90:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.3, 0.6, 0.1])\n",
    "    else:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.1, 0.4, 0.5])\n",
    "\n",
    "df['advisory_50_cutoff'] = df['Risk30DayReadmission'].apply(calculate_column2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent', pd.NA]\n",
    "\n",
    "# # Create advisory columns based on the given conditions with weighted random choices\n",
    "# def calculate_advisory(score, percentile_low, percentile_high, weights):\n",
    "#     if score < percentile_low:\n",
    "#         return np.random.choice(options, p=weights[0])\n",
    "#     elif score < percentile_high:\n",
    "#         return np.random.choice(options, p=weights[1])\n",
    "#     else:\n",
    "#         return np.random.choice(options, p=weights[2])\n",
    "\n",
    "# # Define weights for different questions and advisory columns\n",
    "# weights_30_effectiveness = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.30, 0.30],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_30_impact = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.30, 0.30]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_30_clarity = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_effectiveness = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_impact = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_clarity = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# df['advisory_30_cutoff_effectiveness'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_effectiveness))\n",
    "# df['advisory_30_cutoff_impact'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_impact))\n",
    "# df['advisory_30_cutoff_clarity'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_clarity))\n",
    "\n",
    "# df['advisory_50_cutoff_effectiveness'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_effectiveness))\n",
    "# df['advisory_50_cutoff_impact'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_impact))\n",
    "# df['advisory_50_cutoff_clarity'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_clarity))\n",
    "\n",
    "# # Create satisfaction columns with correlation logic and weighted random choices\n",
    "# def calculate_satisfaction(row, advisory_columns):\n",
    "#     effectiveness_values = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent']\n",
    "    \n",
    "#     effectiveness_count = sum([row[col] in effectiveness_values[:2] for col in advisory_columns])\n",
    "    \n",
    "#     if effectiveness_count >= 2:\n",
    "#         return np.random.choice(options, p=[0.40, 0.30, 0.20, 0.05, 0.05, 0.10])\n",
    "    \n",
    "#     effectiveness_count_high = sum([row[col] in effectiveness_values[3:] for col in advisory_columns])\n",
    "    \n",
    "#     if effectiveness_count_high >= 2:\n",
    "#         return np.random.choice(options, p=[0.05, 0.05, 0.20, 0.30, 0.30, 0.10])\n",
    "    \n",
    "#     return np.random.choice(options, p=[0.20, 0.20, 0.20, 0.20, 0.10, 0.10])\n",
    "\n",
    "# df['advisory_30_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_30_cutoff_effectiveness', 'advisory_30_cutoff_impact', 'advisory_30_cutoff_clarity']), axis=1)\n",
    "# df['advisory_50_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_50_cutoff_effectiveness', 'advisory_50_cutoff_impact', 'advisory_50_cutoff_clarity']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent', pd.NA]\n",
    "\n",
    "# # Create advisory columns based on the given conditions with weighted random choices\n",
    "# def calculate_advisory(score, percentile_low, percentile_high, weights):\n",
    "#     if score < percentile_low:\n",
    "#         return np.random.choice(options, p=weights[0])\n",
    "#     elif score < percentile_high:\n",
    "#         return np.random.choice(options, p=weights[1])\n",
    "#     else:\n",
    "#         return np.random.choice(options, p=weights[2])\n",
    "\n",
    "# # Define weights for different questions and advisory columns\n",
    "# weights_30_effectiveness = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.30, 0.30],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_30_impact = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.30, 0.30]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_30_clarity = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_effectiveness = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_impact = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_clarity = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# df['advisory_30_cutoff_effectiveness'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_effectiveness))\n",
    "# df['advisory_30_cutoff_impact'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_impact))\n",
    "# df['advisory_30_cutoff_clarity'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_clarity))\n",
    "\n",
    "# df['advisory_50_cutoff_effectiveness'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_effectiveness))\n",
    "# df['advisory_50_cutoff_impact'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_impact))\n",
    "# df['advisory_50_cutoff_clarity'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_clarity))\n",
    "\n",
    "# # Create satisfaction columns with correlation logic and weighted random choices\n",
    "# def calculate_satisfaction(row, advisory_columns):\n",
    "#     effectiveness_values = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent']\n",
    "    \n",
    "#     effectiveness_count = sum([row[col] in effectiveness_values[:2] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "#     if effectiveness_count >= 2:\n",
    "#         return np.random.choice(options, p=[0.30, 0.30, 0.20, 0.05, 0.05, 0.10])\n",
    "    \n",
    "#     effectiveness_count_high = sum([row[col] in effectiveness_values[3:] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "#     if effectiveness_count_high >= 2:\n",
    "#         return np.random.choice(options, p=[0.05, 0.05, 0.20, 0.30, 0.30, 0.10])\n",
    "    \n",
    "#     return np.random.choice(options, p=[0.20, 0.20, 0.20, 0.20, 0.10, 0.10])\n",
    "\n",
    "# df['advisory_30_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_30_cutoff_effectiveness', 'advisory_30_cutoff_impact', 'advisory_30_cutoff_clarity']), axis=1)\n",
    "# df['advisory_50_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_50_cutoff_effectiveness', 'advisory_50_cutoff_impact', 'advisory_50_cutoff_clarity']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent', pd.NA]\n",
    "\n",
    "# # Create advisory columns based on the given conditions with weighted random choices\n",
    "# def calculate_advisory(score, percentile_low, percentile_high, weights):\n",
    "#     if score < percentile_low:\n",
    "#         return np.random.choice(options, p=weights[0])\n",
    "#     elif score < percentile_high:\n",
    "#         return np.random.choice(options, p=weights[1])\n",
    "#     else:\n",
    "#         return np.random.choice(options, p=weights[2])\n",
    "\n",
    "# # Define weights for different questions and advisory columns\n",
    "# weights_30_effectiveness = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.30, 0.30],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_30_impact = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.30, 0.30]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_30_clarity = [\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "#     [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "#     [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_effectiveness = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_impact = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# weights_50_clarity = [\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "#     [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "#     [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "# ]\n",
    "\n",
    "# df['advisory_30_cutoff_effectiveness'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_effectiveness))\n",
    "# df['advisory_30_cutoff_impact'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_impact))\n",
    "# df['advisory_30_cutoff_clarity'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_clarity))\n",
    "\n",
    "# df['advisory_50_cutoff_effectiveness'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_effectiveness))\n",
    "# df['advisory_50_cutoff_impact'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_impact))\n",
    "# df['advisory_50_cutoff_clarity'] = df['LGBM_score'].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_clarity))\n",
    "\n",
    "# # Create satisfaction columns with correlation logic and weighted random choices\n",
    "# def calculate_satisfaction(row, advisory_columns):\n",
    "#     effectiveness_values = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent']\n",
    "    \n",
    "#     effectiveness_count = sum([row[col] in effectiveness_values[:2] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "#     if effectiveness_count >= 2:\n",
    "#         return np.random.choice(options, p=[0.30, 0.30, 0.20, 0.05, 0.05, 0.10])\n",
    "    \n",
    "#     effectiveness_count_high = sum([row[col] in effectiveness_values[3:] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "#     if effectiveness_count_high >= 2:\n",
    "#         return np.random.choice(options, p=[0.05, 0.05, 0.20, 0.30, 0.30, 0.10])\n",
    "    \n",
    "#     return np.random.choice(options, p=[0.20, 0.20, 0.20, 0.20, 0.10, 0.10])\n",
    "\n",
    "# df['advisory_30_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_30_cutoff_effectiveness', 'advisory_30_cutoff_impact', 'advisory_30_cutoff_clarity']), axis=1)\n",
    "# df['advisory_50_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_50_cutoff_effectiveness', 'advisory_50_cutoff_impact', 'advisory_50_cutoff_clarity']), axis=1)\n",
    "\n",
    "# # Ensure all columns are NA if satisfaction is NA\n",
    "# def ensure_na(row, advisory_columns):\n",
    "#     if pd.isna(row[advisory_columns[-1]]):\n",
    "#         for col in advisory_columns:\n",
    "#             row[col] = pd.NA\n",
    "#     return row\n",
    "\n",
    "# df = df.apply(lambda row: ensure_na(row, ['advisory_30_cutoff_effectiveness', 'advisory_30_cutoff_impact', 'advisory_30_cutoff_clarity', 'advisory_30_cutoff_satisfaction']), axis=1)\n",
    "# df = df.apply(lambda row: ensure_na(row, ['advisory_50_cutoff_effectiveness', 'advisory_50_cutoff_impact', 'advisory_50_cutoff_clarity', 'advisory_50_cutoff_satisfaction']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## This is the one used\n",
    "column = 'Risk30DayReadmission' # 'RiskAnyReadmission'\n",
    "options = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent', pd.NA]\n",
    "\n",
    "# Calculate percentiles\n",
    "percentile_30 = df[column].quantile(0.30)\n",
    "percentile_50 = df[column].quantile(0.50)\n",
    "percentile_80 = df[column].quantile(0.80)\n",
    "percentile_90 = df[column].quantile(0.90)\n",
    "\n",
    "# Create column1 based on the given conditions with weighted random choices\n",
    "def calculate_column1(score):\n",
    "    if score < percentile_30:\n",
    "        return 'low risk'\n",
    "    elif score < percentile_80:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.45, 0.45, 0.1])\n",
    "    else:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.1, 0.6, 0.3])\n",
    "\n",
    "df['advisory_30_cutoff'] = df[column].apply(calculate_column1)\n",
    "\n",
    "# Create column2 based on the given conditions with weighted random choices\n",
    "def calculate_column2(score):\n",
    "    if score < percentile_50:\n",
    "        return 'low risk'\n",
    "    elif score < percentile_90:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.3, 0.6, 0.1])\n",
    "    else:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.1, 0.4, 0.5])\n",
    "\n",
    "df['advisory_50_cutoff'] = df[column].apply(calculate_column2)\n",
    "\n",
    "# Create advisory columns based on the given conditions with weighted random choices\n",
    "def calculate_advisory(score, percentile_low, percentile_high, weights):\n",
    "    if score < percentile_low:\n",
    "        return np.random.choice(options, p=weights[0])\n",
    "    elif score < percentile_high:\n",
    "        return np.random.choice(options, p=weights[1])\n",
    "    else:\n",
    "        return np.random.choice(options, p=weights[2])\n",
    "\n",
    "# Define weights for different questions and advisory columns\n",
    "weights_30_effectiveness = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.30, 0.30],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "]\n",
    "\n",
    "weights_30_impact = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.30, 0.30]   # High percentile\n",
    "]\n",
    "\n",
    "weights_30_clarity = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "]\n",
    "\n",
    "weights_50_effectiveness = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "weights_50_impact = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "weights_50_clarity = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "df['advisory_30_cutoff_effectiveness'] = df[column].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_effectiveness))\n",
    "df['advisory_30_cutoff_impact'] = df[column].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_impact))\n",
    "df['advisory_30_cutoff_clarity'] = df[column].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_clarity))\n",
    "\n",
    "df['advisory_50_cutoff_effectiveness'] = df[column].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_effectiveness))\n",
    "df['advisory_50_cutoff_impact'] = df[column].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_impact))\n",
    "df['advisory_50_cutoff_clarity'] = df[column].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_clarity))\n",
    "\n",
    "# Create satisfaction columns with correlation logic and weighted random choices for different percentiles\n",
    "def calculate_satisfaction(row, advisory_columns, percentiles):\n",
    "    effectiveness_values = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent']\n",
    "    \n",
    "    effectiveness_count = sum([row[col] in effectiveness_values[:2] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "    if effectiveness_count >= 2:\n",
    "        if row[column] < percentiles[1]:\n",
    "            return np.random.choice(options, p=[0.20, 0.15, 0.15, 0.05, 0.05, 0.40])\n",
    "        elif row[column] < percentiles[2]:\n",
    "            return np.random.choice(options, p=[0.25, 0.20, 0.15, 0.05, 0.05, 0.30])\n",
    "        else:\n",
    "            return np.random.choice(options, p=[0.15, 0.15, 0.10, 0.05, 0.05, 0.50])\n",
    "    \n",
    "    effectiveness_count_high = sum([row[col] in effectiveness_values[3:] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "    if effectiveness_count_high >= 2:\n",
    "        if row[column] < percentiles[1]:\n",
    "            return np.random.choice(options, p=[0.05, 0.05, 0.10, 0.15, 0.15, 0.50])\n",
    "        elif row[column] < percentiles[2]:\n",
    "            return np.random.choice(options, p=[0.05, 0.10, 0.20, 0.20, 0.15, 0.30])\n",
    "        else:\n",
    "            return np.random.choice(options, p=[0.05, 0.05, 0.20, 0.15, 0.15, 0.40])\n",
    "    \n",
    "    if row[column] < percentiles[1]:\n",
    "        return np.random.choice(options, p=[0.05, 0.05, 0.10, 0.15, 0.15, 0.50])\n",
    "    elif row[column] < percentiles[2]:\n",
    "        return np.random.choice(options, p=[0.10, 0.15, 0.20, 0.15, 0.10, 0.30])\n",
    "    else:\n",
    "        return np.random.choice(options, p=[0.05, 0.05, 0.15, 0.15, 0.10, 0.50])\n",
    "\n",
    "df['advisory_30_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_30_cutoff_effectiveness', 'advisory_30_cutoff_impact', 'advisory_30_cutoff_clarity'], [percentile_30, percentile_50, percentile_80]), axis=1)\n",
    "df['advisory_50_cutoff_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_50_cutoff_effectiveness', 'advisory_50_cutoff_impact', 'advisory_50_cutoff_clarity'], [percentile_50, percentile_80, percentile_90]), axis=1)\n",
    "\n",
    "# Ensure all columns are NA if satisfaction is NA\n",
    "def ensure_na(row, advisory_columns):\n",
    "    if pd.isna(row[advisory_columns[-1]]):\n",
    "        for col in advisory_columns:\n",
    "            row[col] = pd.NA\n",
    "    return row\n",
    "\n",
    "df = df.apply(lambda row: ensure_na(row, ['advisory_30_cutoff_effectiveness', 'advisory_30_cutoff_impact', 'advisory_30_cutoff_clarity', 'advisory_30_cutoff_satisfaction']), axis=1)\n",
    "df = df.apply(lambda row: ensure_na(row, ['advisory_50_cutoff_effectiveness', 'advisory_50_cutoff_impact', 'advisory_50_cutoff_clarity', 'advisory_50_cutoff_satisfaction']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('diabetes-v2/data/predictionswithq.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('diabetes/predictionswithq.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>...</th>\n",
       "      <th>ExpectedHospitalStay</th>\n",
       "      <th>ScoringTime</th>\n",
       "      <th>advisory_30_cutoff_effectiveness</th>\n",
       "      <th>advisory_30_cutoff_impact</th>\n",
       "      <th>advisory_30_cutoff_clarity</th>\n",
       "      <th>advisory_50_cutoff_effectiveness</th>\n",
       "      <th>advisory_50_cutoff_impact</th>\n",
       "      <th>advisory_50_cutoff_clarity</th>\n",
       "      <th>advisory_30_cutoff_satisfaction</th>\n",
       "      <th>advisory_50_cutoff_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Other</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>1.875016</td>\n",
       "      <td>2024-10-21 20:55:27.921958</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>5.411178</td>\n",
       "      <td>2024-10-19 20:55:27.922053</td>\n",
       "      <td>Good</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Poor</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-50)</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3.368762</td>\n",
       "      <td>2024-10-20 20:55:27.922060</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[20-50)</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>4.145277</td>\n",
       "      <td>2024-10-20 20:55:27.922063</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Good</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[20-50)</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>2.797394</td>\n",
       "      <td>2024-10-21 20:55:27.922066</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Good</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99335</th>\n",
       "      <td>443847548</td>\n",
       "      <td>100162476</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>70+</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Other</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4.665543</td>\n",
       "      <td>2024-10-19 20:55:28.154977</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>Good</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99336</th>\n",
       "      <td>443847782</td>\n",
       "      <td>74694222</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>70+</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Other</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>5.384318</td>\n",
       "      <td>2024-10-17 20:55:28.154979</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99337</th>\n",
       "      <td>443854148</td>\n",
       "      <td>41088789</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>70+</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>3.004588</td>\n",
       "      <td>2024-10-21 20:55:28.154981</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Good</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Good</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99338</th>\n",
       "      <td>443857166</td>\n",
       "      <td>31693671</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>70+</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Other</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Surgery-General</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>5.517260</td>\n",
       "      <td>2024-10-12 20:55:28.154984</td>\n",
       "      <td>Very Poor</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Good</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99339</th>\n",
       "      <td>443867222</td>\n",
       "      <td>175429310</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>70+</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Discharged to Home</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.133070</td>\n",
       "      <td>2024-10-16 20:55:28.154986</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99340 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      encounter_id patient_nbr             race  gender      age  \\\n",
       "0          2278392     8222157        Caucasian  Female   [0-10)   \n",
       "1           149190    55629189        Caucasian  Female  [10-20)   \n",
       "2            64410    86047875  AfricanAmerican  Female  [20-50)   \n",
       "3           500364    82442376        Caucasian    Male  [20-50)   \n",
       "4            16680    42519267        Caucasian    Male  [20-50)   \n",
       "...            ...         ...              ...     ...      ...   \n",
       "99335    443847548   100162476  AfricanAmerican    Male      70+   \n",
       "99336    443847782    74694222  AfricanAmerican  Female      70+   \n",
       "99337    443854148    41088789        Caucasian    Male      70+   \n",
       "99338    443857166    31693671        Caucasian  Female      70+   \n",
       "99339    443867222   175429310        Caucasian    Male      70+   \n",
       "\n",
       "      admission_type_id discharge_disposition_id admission_source_id  \\\n",
       "0               Unknown                  Unknown            Referral   \n",
       "1             Emergency       Discharged to Home           Emergency   \n",
       "2             Emergency       Discharged to Home           Emergency   \n",
       "3             Emergency       Discharged to Home           Emergency   \n",
       "4             Emergency       Discharged to Home           Emergency   \n",
       "...                 ...                      ...                 ...   \n",
       "99335         Emergency                    Other           Emergency   \n",
       "99336         Emergency                    Other            Transfer   \n",
       "99337         Emergency       Discharged to Home           Emergency   \n",
       "99338         Emergency                    Other           Emergency   \n",
       "99339         Emergency       Discharged to Home           Emergency   \n",
       "\n",
       "      medical_specialty  num_lab_procedures  ...  ExpectedHospitalStay  \\\n",
       "0                 Other                  41  ...              1.875016   \n",
       "1                   NaN                  59  ...              5.411178   \n",
       "2                   NaN                  11  ...              3.368762   \n",
       "3                   NaN                  44  ...              4.145277   \n",
       "4                   NaN                  51  ...              2.797394   \n",
       "...                 ...                 ...  ...                   ...   \n",
       "99335               NaN                  51  ...              4.665543   \n",
       "99336               NaN                  33  ...              5.384318   \n",
       "99337               NaN                  53  ...              3.004588   \n",
       "99338   Surgery-General                  45  ...              5.517260   \n",
       "99339               NaN                  13  ...              2.133070   \n",
       "\n",
       "                     ScoringTime  advisory_30_cutoff_effectiveness  \\\n",
       "0     2024-10-21 20:55:27.921958                              <NA>   \n",
       "1     2024-10-19 20:55:27.922053                              Good   \n",
       "2     2024-10-20 20:55:27.922060                              <NA>   \n",
       "3     2024-10-20 20:55:27.922063                              Poor   \n",
       "4     2024-10-21 20:55:27.922066                         Excellent   \n",
       "...                          ...                               ...   \n",
       "99335 2024-10-19 20:55:28.154977                         Very Poor   \n",
       "99336 2024-10-17 20:55:28.154979                         Very Poor   \n",
       "99337 2024-10-21 20:55:28.154981                         Excellent   \n",
       "99338 2024-10-12 20:55:28.154984                         Very Poor   \n",
       "99339 2024-10-16 20:55:28.154986                              <NA>   \n",
       "\n",
       "       advisory_30_cutoff_impact  advisory_30_cutoff_clarity  \\\n",
       "0                           <NA>                   Excellent   \n",
       "1                      Very Poor                   Very Poor   \n",
       "2                           <NA>                        <NA>   \n",
       "3                           Good                     Neutral   \n",
       "4                           Good                        <NA>   \n",
       "...                          ...                         ...   \n",
       "99335                  Very Poor                        Good   \n",
       "99336                       <NA>                   Excellent   \n",
       "99337                       Good                     Neutral   \n",
       "99338                       <NA>                        Good   \n",
       "99339                       <NA>                        <NA>   \n",
       "\n",
       "      advisory_50_cutoff_effectiveness advisory_50_cutoff_impact  \\\n",
       "0                                 <NA>                      <NA>   \n",
       "1                                 <NA>                      <NA>   \n",
       "2                                 <NA>                      <NA>   \n",
       "3                                 Good                      Good   \n",
       "4                                 Good                      Good   \n",
       "...                                ...                       ...   \n",
       "99335                        Very Poor                   Neutral   \n",
       "99336                             Poor                   Neutral   \n",
       "99337                             <NA>                      <NA>   \n",
       "99338                             <NA>                      <NA>   \n",
       "99339                             <NA>                      <NA>   \n",
       "\n",
       "      advisory_50_cutoff_clarity  advisory_30_cutoff_satisfaction  \\\n",
       "0                           <NA>                        Excellent   \n",
       "1                           <NA>                             Poor   \n",
       "2                           <NA>                             <NA>   \n",
       "3                        Neutral                          Neutral   \n",
       "4                      Very Poor                          Neutral   \n",
       "...                          ...                              ...   \n",
       "99335                       <NA>                          Neutral   \n",
       "99336                    Neutral                             Poor   \n",
       "99337                       <NA>                             Good   \n",
       "99338                       <NA>                          Neutral   \n",
       "99339                       <NA>                             <NA>   \n",
       "\n",
       "      advisory_50_cutoff_satisfaction  \n",
       "0                                <NA>  \n",
       "1                                <NA>  \n",
       "2                                <NA>  \n",
       "3                                Good  \n",
       "4                             Neutral  \n",
       "...                               ...  \n",
       "99335                       Excellent  \n",
       "99336                            Good  \n",
       "99337                            <NA>  \n",
       "99338                            <NA>  \n",
       "99339                            <NA>  \n",
       "\n",
       "[99340 rows x 51 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
