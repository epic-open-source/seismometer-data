{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('diabetes-v2/data/predictionsorig.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encounter_id', 'patient_nbr', 'race', 'gender', 'age',\n",
       "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
       "       'medical_specialty', 'num_lab_procedures', 'num_procedures',\n",
       "       'num_medications', 'number_outpatient', 'number_emergency',\n",
       "       'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses',\n",
       "       'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide',\n",
       "       'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'tolazamide',\n",
       "       'insulin', 'glyburide-metformin', 'change', 'diabetesMed',\n",
       "       'Risk30DayReadmission', 'RiskAnyReadmission',\n",
       "       'Risk30DayReadmissionPercentile', 'RiskLongStay',\n",
       "       'ExpectedHospitalStay', 'ScoringTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## This is the one used\n",
    "column = 'Risk30DayReadmission'\n",
    "options = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent', pd.NA]\n",
    "\n",
    "# Calculate percentiles\n",
    "percentile_30 = df[column].quantile(0.30)\n",
    "percentile_50 = df[column].quantile(0.50)\n",
    "percentile_80 = df[column].quantile(0.80)\n",
    "percentile_90 = df[column].quantile(0.90)\n",
    "\n",
    "# # Create column1 based on the given conditions with weighted random choices\n",
    "def calculate_column1(score):\n",
    "    if score < percentile_30:\n",
    "        return 'low risk'\n",
    "    elif score < percentile_80:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.45, 0.45, 0.1])\n",
    "    else:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.1, 0.6, 0.3])\n",
    "\n",
    "df['CaseManager_Assessment_30_80_Threshold'] = df[column].apply(calculate_column1)\n",
    "\n",
    "# Create advisory columns based on the given conditions with weighted random choices\n",
    "def calculate_advisory(score, percentile_low, percentile_high, weights):\n",
    "    if score < percentile_low:\n",
    "        return np.random.choice(options, p=weights[0])\n",
    "    elif score < percentile_high:\n",
    "        return np.random.choice(options, p=weights[1])\n",
    "    else:\n",
    "        return np.random.choice(options, p=weights[2])\n",
    "\n",
    "# Define weights for different questions and advisory columns\n",
    "weights_30_effectiveness = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.30, 0.30],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "]\n",
    "\n",
    "weights_30_impact = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.30, 0.30]   # High percentile\n",
    "]\n",
    "\n",
    "weights_30_clarity = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "]\n",
    "\n",
    "weights_50_effectiveness = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "weights_50_impact = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "weights_50_clarity = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "df['CaseManager_Feedback_30day_30_80_Threshold_Effectiveness'] = df[column].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_effectiveness))\n",
    "df['CaseManager_Feedback_30day_30_80_Threshold_Impact'] = df[column].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_impact))\n",
    "df['CaseManager_Feedback_30day_30_80_Threshold_Clarity'] = df[column].apply(lambda score: calculate_advisory(score, percentile_30, percentile_80, weights_30_clarity))\n",
    "\n",
    "# Create satisfaction columns with correlation logic and weighted random choices for different percentiles\n",
    "def calculate_satisfaction(row, advisory_columns, percentiles):\n",
    "    effectiveness_values = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent']\n",
    "    \n",
    "    effectiveness_count = sum([row[col] in effectiveness_values[:2] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "    if effectiveness_count >= 2:\n",
    "        if row[column] < percentiles[1]:\n",
    "            return np.random.choice(options, p=[0.20, 0.15, 0.15, 0.05, 0.05, 0.40])\n",
    "        elif row[column] < percentiles[2]:\n",
    "            return np.random.choice(options, p=[0.25, 0.20, 0.15, 0.05, 0.05, 0.30])\n",
    "        else:\n",
    "            return np.random.choice(options, p=[0.15, 0.15, 0.10, 0.05, 0.05, 0.50])\n",
    "    \n",
    "    effectiveness_count_high = sum([row[col] in effectiveness_values[3:] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "    if effectiveness_count_high >= 2:\n",
    "        if row[column] < percentiles[1]:\n",
    "            return np.random.choice(options, p=[0.05, 0.05, 0.10, 0.15, 0.15, 0.50])\n",
    "        elif row[column] < percentiles[2]:\n",
    "            return np.random.choice(options, p=[0.05, 0.10, 0.20, 0.20, 0.15, 0.30])\n",
    "        else:\n",
    "            return np.random.choice(options, p=[0.05, 0.05, 0.20, 0.15, 0.15, 0.40])\n",
    "    \n",
    "    if row[column] < percentiles[1]:\n",
    "        return np.random.choice(options, p=[0.05, 0.05, 0.10, 0.15, 0.15, 0.50])\n",
    "    elif row[column] < percentiles[2]:\n",
    "        return np.random.choice(options, p=[0.10, 0.15, 0.20, 0.15, 0.10, 0.30])\n",
    "    else:\n",
    "        return np.random.choice(options, p=[0.05, 0.05, 0.15, 0.15, 0.10, 0.50])\n",
    "\n",
    "df['PatientSatisfaction_ReadmissionFollowup'] = df.apply(lambda row: calculate_satisfaction(row, [\n",
    "    'CaseManager_Feedback_30day_30_80_Threshold_Effectiveness', 'CaseManager_Feedback_30day_30_80_Threshold_Impact', 'CaseManager_Feedback_30day_30_80_Threshold_Clarity'\n",
    "    ], [percentile_30, percentile_50, percentile_80]), axis=1)\n",
    "\n",
    "# Ensure all columns are NA if satisfaction is NA\n",
    "def ensure_na(row, advisory_columns):\n",
    "    if pd.isna(row[advisory_columns[-1]]):\n",
    "        for col in advisory_columns:\n",
    "            row[col] = pd.NA\n",
    "    return row\n",
    "\n",
    "df = df.apply(lambda row: ensure_na(row, [\n",
    "    'PatientSatisfaction_ReadmissionFollowup',\n",
    "    'CaseManager_Feedback_30day_30_80_Threshold_Effectiveness',\n",
    "    'CaseManager_Feedback_30day_30_80_Threshold_Impact',\n",
    "    'CaseManager_Feedback_30day_30_80_Threshold_Clarity',\n",
    "]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## This is the one used\n",
    "column = 'RiskAnyReadmission'\n",
    "options = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent', pd.NA]\n",
    "\n",
    "# Calculate percentiles\n",
    "percentile_30 = df[column].quantile(0.30)\n",
    "percentile_50 = df[column].quantile(0.50)\n",
    "percentile_80 = df[column].quantile(0.80)\n",
    "percentile_90 = df[column].quantile(0.90)\n",
    "\n",
    "# Create column2 based on the given conditions with weighted random choices\n",
    "def calculate_column2(score):\n",
    "    if score < percentile_50:\n",
    "        return 'low risk'\n",
    "    elif score < percentile_90:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.3, 0.6, 0.1])\n",
    "    else:\n",
    "        return np.random.choice(['low risk', 'neutral', 'high risk'], p=[0.1, 0.4, 0.5])\n",
    "\n",
    "df['advisory_Any_Readmission'] = df[column].apply(calculate_column2)\n",
    "\n",
    "# Create advisory columns based on the given conditions with weighted random choices\n",
    "def calculate_advisory(score, percentile_low, percentile_high, weights):\n",
    "    if score < percentile_low:\n",
    "        return np.random.choice(options, p=weights[0])\n",
    "    elif score < percentile_high:\n",
    "        return np.random.choice(options, p=weights[1])\n",
    "    else:\n",
    "        return np.random.choice(options, p=weights[2])\n",
    "\n",
    "# Define weights for different questions and advisory columns\n",
    "weights_30_effectiveness = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.30, 0.30],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "]\n",
    "\n",
    "weights_30_impact = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.30, 0.30]   # High percentile\n",
    "]\n",
    "\n",
    "weights_30_clarity = [\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35],  # Low percentile\n",
    "    [0.10, 0.10, 0.20, 0.30, 0.20, 0.10],  # Mid percentile\n",
    "    [0.05, 0.05, 0.10, 0.20, 0.25, 0.35]   # High percentile\n",
    "]\n",
    "\n",
    "weights_50_effectiveness = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "weights_50_impact = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "weights_50_clarity = [\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10],   # Low percentile\n",
    "    [0.15, 0.15, 0.25, 0.25, 0.15, 0.05],   # Mid percentile\n",
    "    [0.05, 0.05, 0.15, 0.25, 0.40, 0.10]    # High percentile\n",
    "]\n",
    "\n",
    "df['advisory_any_effectiveness'] = df[column].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_effectiveness))\n",
    "df['advisory_any_impact'] = df[column].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_impact))\n",
    "df['advisory_any_clarity'] = df[column].apply(lambda score: calculate_advisory(score, percentile_50, percentile_90, weights_50_clarity))\n",
    "\n",
    "# Create satisfaction columns with correlation logic and weighted random choices for different percentiles\n",
    "def calculate_satisfaction(row, advisory_columns, percentiles):\n",
    "    effectiveness_values = ['Very Poor', 'Poor', 'Neutral', 'Good', 'Excellent']\n",
    "    \n",
    "    effectiveness_count = sum([row[col] in effectiveness_values[:2] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "    if effectiveness_count >= 2:\n",
    "        if row[column] < percentiles[1]:\n",
    "            return np.random.choice(options, p=[0.20, 0.15, 0.15, 0.05, 0.05, 0.40])\n",
    "        elif row[column] < percentiles[2]:\n",
    "            return np.random.choice(options, p=[0.25, 0.20, 0.15, 0.05, 0.05, 0.30])\n",
    "        else:\n",
    "            return np.random.choice(options, p=[0.15, 0.15, 0.10, 0.05, 0.05, 0.50])\n",
    "    \n",
    "    effectiveness_count_high = sum([row[col] in effectiveness_values[3:] for col in advisory_columns if pd.notna(row[col])])\n",
    "    \n",
    "    if effectiveness_count_high >= 2:\n",
    "        if row[column] < percentiles[1]:\n",
    "            return np.random.choice(options, p=[0.05, 0.05, 0.10, 0.15, 0.15, 0.50])\n",
    "        elif row[column] < percentiles[2]:\n",
    "            return np.random.choice(options, p=[0.05, 0.10, 0.20, 0.20, 0.15, 0.30])\n",
    "        else:\n",
    "            return np.random.choice(options, p=[0.05, 0.05, 0.20, 0.15, 0.15, 0.40])\n",
    "    \n",
    "    if row[column] < percentiles[1]:\n",
    "        return np.random.choice(options, p=[0.05, 0.05, 0.10, 0.15, 0.15, 0.50])\n",
    "    elif row[column] < percentiles[2]:\n",
    "        return np.random.choice(options, p=[0.10, 0.15, 0.20, 0.15, 0.10, 0.30])\n",
    "    else:\n",
    "        return np.random.choice(options, p=[0.05, 0.05, 0.15, 0.15, 0.10, 0.50])\n",
    "\n",
    "df['advisory_any_satisfaction'] = df.apply(lambda row: calculate_satisfaction(row, ['advisory_any_effectiveness', 'advisory_any_impact', 'advisory_any_clarity'], [percentile_50, percentile_80, percentile_90]), axis=1)\n",
    "\n",
    "# Ensure all columns are NA if satisfaction is NA\n",
    "def ensure_na(row, advisory_columns):\n",
    "    if pd.isna(row[advisory_columns[-1]]):\n",
    "        for col in advisory_columns:\n",
    "            row[col] = pd.NA\n",
    "    return row\n",
    "\n",
    "df = df.apply(lambda row: ensure_na(row, ['advisory_any_effectiveness', 'advisory_any_impact', 'advisory_any_clarity', 'advisory_any_satisfaction']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('diabetes-v2/data/predictions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
